{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-7a40fdd6a8cb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mROOT_DIR\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# To find local version of the library\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mmrcnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mConfig\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mmrcnn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mutils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmrcnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmodellib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mmrcnn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mvisualize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\Mask_RCNN\\mrcnn\\utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mrandom\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mskimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# minimum input size = 128\n",
    "class ShapesConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"fibroblast\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "    NUM_CLASSES = 1 + 2  # background + 2 young and old\n",
    "    IMAGE_MIN_DIM = 10\n",
    "    IMAGE_MAX_DIM = 128\n",
    "    RPN_ANCHOR_SCALES = (2, 4, 8, 16, 32)  # anchor side in pixels\n",
    "    TRAIN_ROIS_PER_IMAGE = 8\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    VALIDATION_STEPS = 5\n",
    "config = ShapesConfig()\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "class ShapesDataset(utils.Dataset):\n",
    "    def list_images(self,data_dir):\n",
    "        # Add classes\n",
    "        self.add_class(\"fibroblast\",1,CLASS_NAMES[0])\n",
    "        self.add_class(\"fibroblast\",2,CLASS_NAMES[1])\n",
    "        train_images = list(data_dir.glob('*\\*\\image\\*.jpg'))\n",
    "\n",
    "        # Add images\n",
    "        for idx,train_image in enumerate(train_images):\n",
    "            ground = os.path.normpath(train_image).split(os.path.sep)[-4]\n",
    "            self.add_image(\"fibroblast\",image_id=idx,path=train_image,truth=ground,\n",
    "                           height=config.IMAGE_SHAPE[0],width=config.IMAGE_SHAPE[1])\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        # Load image\n",
    "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if image.ndim != 3:\n",
    "            image = skimage.color.gray2rgb(image)\n",
    "        # If has an alpha channel, remove it for consistency\n",
    "        if image.shape[-1] == 4:\n",
    "            image = image[..., :3]\n",
    "        return image\n",
    "\n",
    "    # def list_masks(self,data_dir):\n",
    "    #     self.add_class(\"fibroblast\",1,CLASS_NAMES[0])\n",
    "    #     self.add_class(\"fibroblast\",2,CLASS_NAMES[1])\n",
    "    #     label_images = list(data_dir.glob('*\\*\\label\\*.jpg'))\n",
    "    #     for idx,label_image in enumerate(label_images):\n",
    "    #         ground = os.path.normpath(label_image).split(os.path.sep)[-4]\n",
    "    #         self.add_image(\"fibroblast\",image_id=idx,path=label_image,truth=ground,\n",
    "    #                        height=config.IMAGE_SHAPE[0],width=config.IMAGE_SHAPE[1])\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        # Load binary mask\n",
    "        info = self.image_info[image_id]\n",
    "        impath = info['path']\n",
    "        maskpath = pathlib.Path(str(impath).replace(\"image\", \"label\"))\n",
    "        instancenum = 1\n",
    "        mask = np.zeros([info['height'], info['width'], instancenum], dtype=np.uint8)\n",
    "        label = info['truth']\n",
    "        # 0 is background\n",
    "        labelidx = np.argwhere(CLASS_NAMES == label).flat[0]+1\n",
    "        # print(label)\n",
    "        # print(labelidx)\n",
    "        masklayer = skimage.io.imread(maskpath)\n",
    "        # print(masklayer.shape)\n",
    "        masklayer = resize(masklayer,(128,128))\n",
    "        # print(masklayer.shape)\n",
    "        thresh = threshold_otsu(masklayer)\n",
    "        binary = masklayer > thresh\n",
    "        # plt.imshow(binary)\n",
    "        mask[:, :, 0] = binary\n",
    "        class_ids = np.array([labelidx])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"fibroblast\":\n",
    "            return info[\"truth\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "data_dir = pathlib.Path(r'C:\\Users\\kuki\\OneDrive - Johns Hopkins\\Research\\Skin\\RCNN data\\RCNNtrain')\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \".DS_store\"])\n",
    "print(CLASS_NAMES)\n",
    "\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.list_images(data_dir)\n",
    "dataset_train.prepare()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir_val = pathlib.Path(r'C:\\Users\\kuki\\OneDrive - Johns Hopkins\\Research\\Skin\\RCNN data\\RCNNtest')\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.list_images(data_dir_val)\n",
    "dataset_val.prepare()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    image = resize(image,(128,128,3))\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print(class_ids)\n",
    "    # print(np.sum(mask))\n",
    "    # print(dataset_train.class_names)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(dataset_val.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_val.load_image(image_id)\n",
    "    image = resize(image,(128,128,3))\n",
    "    mask, class_ids = dataset_val.load_mask(image_id)\n",
    "    print(class_ids)\n",
    "    # print(np.sum(mask))\n",
    "    # print(dataset_val.class_names)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_val.class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=1,\n",
    "            layers='heads')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also\n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2,\n",
    "            layers=\"all\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_MAX_DIM = 128\n",
    "inference_config = InferenceConfig()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# class ShapesConfig(Config):\n",
    "#     # Give the configuration a recognizable name\n",
    "#     NAME = \"fibroblast\"\n",
    "#     GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU = 8\n",
    "#     NUM_CLASSES = 1 + 2  # background + 2 young and old\n",
    "#     IMAGE_MIN_DIM = 10\n",
    "#     IMAGE_MAX_DIM = 128\n",
    "#     RPN_ANCHOR_SCALES = (2, 4, 8, 16, 32)  # anchor side in pixels\n",
    "#     TRAIN_ROIS_PER_IMAGE = 8\n",
    "#     STEPS_PER_EPOCH = 100\n",
    "#     VALIDATION_STEPS = 5\n",
    "\n",
    "\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, image_id)\n",
    "gt_mask = resize(gt_mask,(128,128,1))\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],\n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "\n",
    "print(\"mAP: \", np.mean(APs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}