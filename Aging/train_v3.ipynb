{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kuki\\anaconda3\\envs\\aging\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\kuki\\anaconda3\\envs\\aging\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\kuki\\anaconda3\\envs\\aging\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\kuki\\anaconda3\\envs\\aging\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\kuki\\anaconda3\\envs\\aging\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\kuki\\anaconda3\\envs\\aging\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version 2.2.5\n",
      "tf version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import skimage\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)  # To find loca\n",
    "# l version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# minimum input size = 128\n",
    "class ShapesConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"skin\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 16\n",
    "    NUM_CLASSES = 1 + 2  # background + 2 types\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "    RPN_ANCHOR_SCALES = (16,32,64,128,256)  # anchor side in pixels\n",
    "    TRAIN_ROIS_PER_IMAGE = 8\n",
    "    STEPS_PER_EPOCH = 1152 // IMAGES_PER_GPU\n",
    "    VALIDATION_STEPS = 1152 // IMAGES_PER_GPU\n",
    "    LEARNING_RATE = 0.001\n",
    "    USE_MINI_MASK = False\n",
    "    # gpu_options = True\n",
    "config = ShapesConfig()\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "class ShapesDataset(utils.Dataset):\n",
    "    def list_images(self,data_dir):\n",
    "        # define classes\n",
    "        self.add_class(\"skin\", 1, \"fibroblast\")\n",
    "        self.add_class(\"skin\", 2, \"falsePositive\")\n",
    "\n",
    "        # data_dir = pathlib.Path('/home/kuki/Desktop/novo/')\n",
    "        # register images\n",
    "        train_images = list(data_dir.glob('*/image/*.png'))\n",
    "        print('# image in this dataset : ',len(train_images))\n",
    "        for idx,train_image in enumerate(train_images):\n",
    "            label = str(train_image).replace(\"image\",\"mask\")\n",
    "            self.add_image(\"skin\",image_id=idx,path=train_image,labelpath=label,\n",
    "                           height=config.IMAGE_SHAPE[0],width=config.IMAGE_SHAPE[1])\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if image.ndim != 3:\n",
    "            print('grayscale to rgb')\n",
    "            image = skimage.color.gray2rgb(image)\n",
    "        # If has an alpha channel, remove it for consistency\n",
    "        if image.shape[-1] == 4:\n",
    "            print('rgba to rgb')\n",
    "            image = image[..., :3]\n",
    "        # image = cv2.resize(image,dsize=(256,256))\n",
    "        return image.astype(np.uint8)\n",
    "\n",
    "    # def load_mask(self, image_id):\n",
    "    #     label = self.image_info[image_id]['labelpath']\n",
    "    #     mask = np.load(label.replace('.tif','mask.npy'))\n",
    "    #     class_ids = np.load(label.replace('.tif','classids.npy'))\n",
    "    #     class_ids = class_ids + 1\n",
    "    #     return mask,class_ids\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        label = self.image_info[image_id]['labelpath']\n",
    "        mask = Image.open(label)\n",
    "        mask = np.array(mask).astype('int')\n",
    "        mask = mask[:,:,np.newaxis]\n",
    "        if 'false_positive' in label:\n",
    "            class_ids = np.array([2])\n",
    "        else:\n",
    "            class_ids = np.array([1])\n",
    "        return mask,class_ids\n",
    "\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"skin\":\n",
    "            return info[\"truth\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# image in this dataset :  0\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(r'\\\\kukissd\\Kyu_Sync\\Aging\\data\\svs\\20x\\segmentation')\n",
    "# CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \".DS_store\"])\n",
    "# print(CLASS_NAMES)\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.list_images(data_dir)\n",
    "dataset_train.prepare()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# image in this dataset :  0\n"
     ]
    }
   ],
   "source": [
    "data_dir_val = pathlib.Path(r'\\\\kukissd\\Kyu_Sync\\Aging\\data\\svs\\20x\\segmentation')\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.list_images(data_dir_val)\n",
    "dataset_val.prepare()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-97ca387d6230>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mimage_ids\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mimage_id\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mimage_ids\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;31m# start = time.time()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdataset_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage_id\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mmtrand.pyx\u001B[0m in \u001B[0;36mnumpy.random.mtrand.RandomState.choice\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "import time\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 5)\n",
    "for image_id in image_ids:\n",
    "    # start = time.time()\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    # end = time.time()\n",
    "    # print(np.around(end-start))\n",
    "    # start = time.time()\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print(class_ids)\n",
    "    # print(mask.shape)\n",
    "    # end = time.time()\n",
    "    # print(np.around(end-start))\n",
    "    # print(np.around(mask.shape[2]/(end-start)),'image per sec')\n",
    "    # visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(dataset_val.image_ids, 5)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_val.load_image(image_id)\n",
    "    mask, class_ids = dataset_val.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_val.class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_area = np.sum(mask[:, :, 0])\n",
    "mask_area"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_val.image_info[image_id]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add augmentation and mask resizing.\n",
    "image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "    dataset_train, config, image_id,\n",
    "    augmentation=imgaug.augmenters.Fliplr(0.5), use_mini_mask=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "augmentation = iaa.Sometimes(0.9, [\n",
    "    iaa.color.AddToHueAndSaturation((-10,10)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.OneOf([iaa.Affine(rotate=90),\n",
    "                   iaa.Affine(rotate=180),\n",
    "                   iaa.Affine(rotate=270)]),\n",
    "    iaa.Multiply((0.8, 1.2)),\n",
    "    iaa.GaussianBlur(sigma=(0.0, 1.0)),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limit = 4\n",
    "ax = get_ax(rows=2, cols=limit//2)\n",
    "for i in range(limit):\n",
    "    image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "        dataset_train, config, image_id, use_mini_mask=False, augment=False, augmentation=augmentation)\n",
    "    visualize.display_instances(image, bbox, mask, class_ids,\n",
    "                                dataset_train.class_names, ax=ax[i//2, i % 2],\n",
    "                                show_mask=False, show_bbox=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=30,\n",
    "            augmentation=augmentation,\n",
    "            layers='heads')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also\n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=50,\n",
    "            augmentation=imgaug.augmenters.Fliplr(0.5),\n",
    "            layers=\"all\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# class InferenceConfig(ShapesConfig):\n",
    "#     GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU = 1\n",
    "#     IMAGE_MAX_DIM = 128\n",
    "# inference_config = InferenceConfig()\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Recreate the model in inference mode\n",
    "# model = modellib.MaskRCNN(mode=\"inference\",\n",
    "#                           config=inference_config,\n",
    "#                           model_dir=MODEL_DIR)\n",
    "#\n",
    "# # Get path to saved weights\n",
    "# # Either set a specific path or find last trained weights\n",
    "# # model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "# model_path = model.find_last()\n",
    "#\n",
    "# # Load trained weights\n",
    "# print(\"Loading weights from \", model_path)\n",
    "# model.load_weights(model_path, by_name=True)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Test on a random image\n",
    "# image_id = random.choice(dataset_train.image_ids)\n",
    "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#     modellib.load_image_gt(dataset_train, inference_config, image_id)\n",
    "#\n",
    "# log(\"original_image\", original_image)\n",
    "# log(\"image_meta\", image_meta)\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)\n",
    "#\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# results = model.detect([original_image], verbose=1)\n",
    "#\n",
    "# r = results[0]\n",
    "# visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],\n",
    "#                             dataset_val.class_names, r['scores'], ax=get_ax())\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Compute VOC-Style mAP @ IoU=0.5\n",
    "# # Running on 10 images. Increase for better accuracy.\n",
    "# image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "# APs = []\n",
    "# for image_id in image_ids:\n",
    "#     # Load image and ground truth data\n",
    "#     image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#         modellib.load_image_gt(dataset_val, inference_config,\n",
    "#                                image_id, use_mini_mask=False)\n",
    "#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "#     # Run object detection\n",
    "#     results = model.detect([image], verbose=0)\n",
    "#     r = results[0]\n",
    "#     # Compute AP\n",
    "#     AP, precisions, recalls, overlaps =\\\n",
    "#         utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "#                          r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "#     APs.append(AP)\n",
    "#\n",
    "# print(\"mAP: \", np.mean(APs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}